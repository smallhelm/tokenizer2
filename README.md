# tokenizer2
tokenize any text stream given some basic regex rules to match tokens
